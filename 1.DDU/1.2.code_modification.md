<!--
 * @FilePath: 1.2.code_modification.md
 * @Author: erchen
 * @Date: 2024-08-17 16:22:50
 * @LastEditTime: 2024-08-19 16:11:07
 * @Descripttion: 
-->

- [修改数据集存放目录](#修改数据集存放目录)
- [简化命名](#简化命名)
- [保存模型 last epoch](#保存模型-last-epoch)
- [将参数写入文件并保存](#将参数写入文件并保存)
- [修改 writer](#修改-writer)
- [修改模型加载路径](#修改模型加载路径)

以下修改根据个人修改顺序列举。

**注意：以下修改仅为个人调试方便进行，代码错误的地方已在1.1进行修改。不进行以下修改，代码也可运行。但后续命令行参数基于以下修改。**

# 修改数据集存放目录

数据集存放与数据处理的代码在同一个目录，较为混乱，修改数据集存放的目录，并将该路径写入 '.gitignore' 文件中。

```vim
dataset/
```

修改内容有：

- 将 cifar10，cifar100 数据集的存放目录改为 'dataset/'
- 将 SVHN 数据集的存放目录改为 'dataset/SVHN'

```git
diff --git a/data/ood_detection/cifar10.py b/data/ood_detection/cifar10.py
index 082f45d..17503a0 100644
--- a/data/ood_detection/cifar10.py
+++ b/data/ood_detection/cifar10.py
@@ -50,7 +50,7 @@ def get_train_valid_loader(batch_size, augment, val_seed, val_size=0.1, num_work
         train_transform = transforms.Compose([transforms.ToTensor(), normalize,])
 
     # load the dataset
-    data_dir = "./data"
+    data_dir = "./dataset"
     train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=train_transform,)
 
     valid_dataset = datasets.CIFAR10(root=data_dir, train=True, download=False, transform=valid_transform,)
@@ -97,7 +97,7 @@ def get_test_loader(batch_size, num_workers=4, pin_memory=False, **kwargs):
     # define transform
     transform = transforms.Compose([transforms.ToTensor(), normalize,])
 
-    data_dir = "./data"
+    data_dir = "./dataset"
     dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform,)
 
     data_loader = torch.utils.data.DataLoader(
diff --git a/data/ood_detection/cifar100.py b/data/ood_detection/cifar100.py
index feb1464..4ef59c8 100644
--- a/data/ood_detection/cifar100.py
+++ b/data/ood_detection/cifar100.py
@@ -50,7 +50,7 @@ def get_train_valid_loader(batch_size, augment, val_seed, val_size=0.1, num_work
         train_transform = transforms.Compose([transforms.ToTensor(), normalize,])
 
     # load the dataset
-    data_dir = "./data"
+    data_dir = "./dataset"
     train_dataset = datasets.CIFAR100(root=data_dir, train=True, download=True, transform=train_transform,)
 
     valid_dataset = datasets.CIFAR100(root=data_dir, train=True, download=False, transform=valid_transform,)
@@ -97,7 +97,7 @@ def get_test_loader(batch_size, num_workers=4, pin_memory=False, **kwargs):
     # define transform
     transform = transforms.Compose([transforms.ToTensor(), normalize,])
 
-    data_dir = "./data"
+    data_dir = "./dataset"
     dataset = datasets.CIFAR100(root=data_dir, train=False, download=True, transform=transform,)
 
     data_loader = torch.utils.data.DataLoader(
diff --git a/data/ood_detection/svhn.py b/data/ood_detection/svhn.py
index 0ea74c8..ac36b1b 100644
--- a/data/ood_detection/svhn.py
+++ b/data/ood_detection/svhn.py
@@ -37,7 +37,7 @@ def get_train_valid_loader(batch_size, augment, val_seed, val_size=0.1, num_work
     valid_transform = transforms.Compose([transforms.ToTensor(), normalize,])
 
     # load the dataset
-    data_dir = "./data"
+    data_dir = "./dataset/SVHN"
     train_dataset = datasets.SVHN(root=data_dir, split="train", download=True, transform=valid_transform,)
 
     valid_dataset = datasets.SVHN(root=data_dir, split="train", download=True, transform=valid_transform,)
@@ -83,7 +83,7 @@ def get_test_loader(batch_size, num_workers=4, pin_memory=False, **kwargs):
     # define transform
     transform = transforms.Compose([transforms.ToTensor(), normalize,])
 
-    data_dir = "./data"
+    data_dir = "./dataset/SVHN"
     dataset = datasets.SVHN(root=data_dir, split="test", download=True, transform=transform,)
 
     data_loader = torch.utils.data.DataLoader(
```

# 简化命名

简化保存的模型命名，修改后的模型命名：

- 深度集成：'{model_name}_epoch{当前epoch}_{集成模型序号}.model'
- 单个模型：'{model_name}_epoch{当前epoch}.model'

```git
diff --git a/train.py b/train.py
index 237868d..b6d80d6 100644
--- a/train.py
+++ b/train.py
@@ -120,7 +120,7 @@ if __name__ == "__main__":
         scheduler.step()
 
         if (epoch + 1) % args.save_interval == 0:
-            saved_name = args.save_loc + save_name + "_" + str(epoch + 1) + ".model"
+            saved_name = args.save_loc + args.model + "_epoch" + str(epoch + 1) + ".model"
             torch.save(net.state_dict(), saved_name)
 
     saved_name = args.save_loc + save_name + "_" + str(epoch + 1) + ".model"
diff --git a/train_ensemble.py b/train_ensemble.py
index 83eb1d6..da9f7e6 100644
--- a/train_ensemble.py
+++ b/train_ensemble.py
@@ -104,9 +104,8 @@ if __name__ == "__main__":
             schedulers[i].step()
 
         writer.add_scalar(args.model + "_ensemble_" + "train_loss", train_loss, (epoch + 1))
-        save_name = model_save_name(args.model, args.sn, args.mod, args.coeff, args.seed)
         if (epoch + 1) % args.save_interval == 0:
             for i, model in enumerate(net_ensemble):
-                save_name = args.save_loc + save_name + str(args.seed+i) + "_" + str(epoch + 1) + ".model"
+                save_name = args.save_loc + args.model + "_epoch" + str(epoch + 1) + "_" + str(i) + ".model"
                 torch.save(model.state_dict(), save_name)
     writer.close()
```

# 保存模型 last epoch

保存训练完所有轮次的模型，并统一命名，用于后续评估。同时去除了一些非必要内容。

命名为：

- 深度集成：'{model_name}_epoch_last_{集成模型序号}.model'
- 单个模型：'{model_name}_epoch_last.model'

```git
diff --git a/train.py b/train.py
index b6d80d6..53036a8 100644
--- a/train.py
+++ b/train.py
@@ -103,19 +103,14 @@ if __name__ == "__main__":
     # Creating summary writer in tensorboard
     writer = SummaryWriter(args.save_loc + "stats_logging/")
 
-    training_set_loss = {}
-
-    save_name = model_save_name(args.model, args.sn, args.mod, args.coeff, args.seed)
-    print("Model save name", save_name)
-
     for epoch in range(0, args.epoch):
         print("Starting epoch", epoch)
         train_loss = train_single_epoch(
             epoch, net, train_loader, optimizer, device, loss_function=args.loss_function, loss_mean=args.loss_mean,
         )
 
-        training_set_loss[epoch] = train_loss
-        writer.add_scalar(save_name + "_train_loss", train_loss, (epoch + 1))
+        writer.add_scalar(args.model + "_train_loss", train_loss, (epoch + 1))
 
         scheduler.step()
 
@@ -123,10 +118,8 @@ if __name__ == "__main__":
             saved_name = args.save_loc + args.model + "_epoch" + str(epoch + 1) + ".model"
             torch.save(net.state_dict(), saved_name)
 
-    saved_name = args.save_loc + save_name + "_" + str(epoch + 1) + ".model"
+    saved_name = args.save_loc + args.model + "_epoch_last.model"
     torch.save(net.state_dict(), saved_name)
     print("Model saved to ", saved_name)
 
-    writer.close()
-    with open(saved_name[: saved_name.rfind("_")] + "_train_loss.json", "a") as f:
-        json.dump(training_set_loss, f)
+    writer.close()
\ No newline at end of file
diff --git a/train_ensemble.py b/train_ensemble.py
index da9f7e6..9b919ca 100644
--- a/train_ensemble.py
+++ b/train_ensemble.py
@@ -108,4 +108,7 @@ if __name__ == "__main__":
             for i, model in enumerate(net_ensemble):
                 save_name = args.save_loc + args.model + "_epoch" + str(epoch + 1) + "_" + str(i) + ".model"
                 torch.save(model.state_dict(), save_name)
+    for i, model in enumerate(net_ensemble):
+        save_name = args.save_loc + args.model + "_epoch_last_" + str(i) + ".model"
+        torch.save(model.state_dict(), save_name)
     writer.close()
```

# 将参数写入文件并保存

将命令行参数写入json文件，并保存。

```git
diff --git a/train.py b/train.py
index 53036a8..f66f5da 100644
--- a/train.py
+++ b/train.py
@@ -122,4 +122,8 @@ if __name__ == "__main__":
     torch.save(net.state_dict(), saved_name)
     print("Model saved to ", saved_name)
 
-    writer.close()
\ No newline at end of file
+    writer.close()
+
+    import json
+    with open(args.save_loc + 'args.json', 'w') as file:
+        json.dump(vars(args), file, indent=4)
\ No newline at end of file
diff --git a/train_ensemble.py b/train_ensemble.py
index 9b919ca..9b45536 100644
--- a/train_ensemble.py
+++ b/train_ensemble.py
@@ -112,3 +112,7 @@ if __name__ == "__main__":
         save_name = args.save_loc + args.model + "_epoch_last_" + str(i) + ".model"
         torch.save(model.state_dict(), save_name)
     writer.close()
+
+    import json
+    with open(args.save_loc + 'args.json', 'w') as file:
+        json.dump(vars(args), file, indent=4)
\ No newline at end of file
```

# 修改 writer

集成网络训练中，writer只记录了集成中最后一个网络的损失变化，修改为记录所有网络的变化。

```git
diff --git a/train_ensemble.py b/train_ensemble.py
index 9b45536..8501de4 100644
--- a/train_ensemble.py
+++ b/train_ensemble.py
@@ -102,8 +102,8 @@ if __name__ == "__main__":
                 epoch, model, train_loaders[i], optimizers[i], device, loss_mean=args.loss_mean,
             )
             schedulers[i].step()
+            writer.add_scalar(args.model + "_ensemble_" + str(i) + "_train_loss", train_loss, (epoch + 1))
 
-        writer.add_scalar(args.model + "_ensemble_" + "train_loss", train_loss, (epoch + 1))
         if (epoch + 1) % args.save_interval == 0:
             for i, model in enumerate(net_ensemble):
                 save_name = args.save_loc + args.model + "_epoch" + str(epoch + 1) + "_" + str(i) + ".model"
```

# 修改模型加载路径

在之前对模型保存的路径进行修改后，评估脚本中关于模型加载的路径也需要修改。修改内容有：

- 修改模型加载路径。
- 原代码默认深度集成模型数量为5，不可更改。修改后将深度集成模型数量作为参数传入，可修改。
- 模型加载时，使用weights_only=True参数，可以限制在反序列化过程中可能执行的函数，提高安全性。
- 模型加载时使用了 `DataParallel` 包装模型，但训练时没有使用，导致加载模型时，参数的 key 无法对应，故删去。

```git
diff --git a/evaluate.py b/evaluate.py
index 0b8ec2f..97238ec 100644
--- a/evaluate.py
+++ b/evaluate.py
@@ -109,6 +109,7 @@ if __name__ == "__main__":
                 model_name=args.model,
                 device=device,
                 num_classes=num_classes,
+                ensemble_len=args.ensemble,
                 spectral_normalization=args.sn,
                 mod=args.mod,
                 coeff=args.coeff,
@@ -122,7 +123,7 @@ if __name__ == "__main__":
             saved_model_name = os.path.join(
                 args.load_loc,
                 "Run" + str(i + 1),
-                model_load_name(args.model, args.sn, args.mod, args.coeff, args.seed, i) + "_350.model",
+                args.model + '_epoch_last.model'
             )
             net = models[args.model](
                 spectral_normalization=args.sn, mod=args.mod, coeff=args.coeff, num_classes=num_classes, temp=1.0,
@@ -131,7 +132,7 @@ if __name__ == "__main__":
                 net.cuda()
                 net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))
                 cudnn.benchmark = True
-            net.load_state_dict(torch.load(str(saved_model_name)))
+            net.load_state_dict(torch.load(str(saved_model_name), weights_only=True))
             net.eval()
 
         # Evaluating the model(s)
diff --git a/utils/ensemble_utils.py b/utils/ensemble_utils.py
index 7a5d5e7..79e0696 100644
--- a/utils/ensemble_utils.py
+++ b/utils/ensemble_utils.py
@@ -28,9 +28,9 @@ def load_ensemble(ensemble_loc, model_name, device, num_classes=10, ensemble_len
     cudnn.benchmark = True
     for i in range(ensemble_len):
         net = models[model_name](num_classes=num_classes, temp=1.0, **kwargs).to(device)
-        net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))
+        # net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))
         net.load_state_dict(
-            torch.load(ensemble_loc + '/' + model_name + '_' + str(seed+i) + "_" + str(num_epochs) + ".model")
+            torch.load(ensemble_loc + '/' + model_name + '_epoch_last_' + str(i) + ".model", weights_only=True)
         )
         ensemble.append(net)
     return ensemble
```