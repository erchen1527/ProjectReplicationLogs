<!--
 * @FilePath: 1.4.code_details.md
 * @Author: erchen
 * @Date: 2024-08-16 15:29:37
 * @LastEditTime: 2024-08-17 21:10:51
 * @Descripttion: 代码细节记录
-->

- [参数](#参数)
  - [spectral normalization 谱归一化](#spectral-normalization-谱归一化)
  - [architectural modifications 架构修改](#architectural-modifications-架构修改)
  - [lr\_scheduler 学习率调度器](#lr_scheduler-学习率调度器)
- [数据集加载](#数据集加载)
  - [get\_train\_valid\_loader()](#get_train_valid_loader)
  - [get\_test\_loader()](#get_test_loader)
- [训练](#训练)
  - [training deep ensemble models](#training-deep-ensemble-models)
  - [training a single model for OOD detection](#training-a-single-model-for-ood-detection)
  - [train\_single\_epoch()](#train_single_epoch)

# 参数

## spectral normalization 谱归一化

- `sn`: 是否使用谱归一化
- `coeff`: 谱归一化的参数

ResNet, VGG, WideResNet 类中定义了 wrapped_conv 函数，自定义卷积层，应用于整个网络。该卷积层根据参数 sn，决定是否应用谱归一化（spectral normalization）。

wrapped_conv 函数接收以下参数：

- `input_size`: 输入特征图的尺寸。
- `in_c`: 输入通道数。
- `out_c`: 输出通道数。
- `kernel_size`: 卷积核的大小。
- `stride`: 卷积的步长。

wrapped_conv 函数实现如下：

* 卷积层创建：
   - 使用 `nn.Conv2d` 创建一个二维卷积层。如果 `kernel_size` 等于 3，则填充设置为 1，否则为 0。这样做是为了保持特征图的空间尺寸不变。
* 谱归一化：
   - 根据参数 sn，决定是否对卷积层应用谱归一化
   - 谱归一化有两种形式，取决于卷积核的大小：
      - 对于 1x1 卷积，使用 `spectral_norm_fc` 函数，因为 1x1 卷积的范数界限较紧。
      - 对于更大尺寸的卷积核，使用 `spectral_norm_conv` 函数。
* 返回值：
   - 如果没有应用谱归一化，直接返回创建的卷积层 `conv`。
   - 如果应用了谱归一化，返回经过谱归一化处理的卷积层 `wrapped_conv`。

## architectural modifications 架构修改

- `mod`: 决定训练期间是否进行架构修改。

架构修改包括两部分：

**（1）使用 LeakyReLU 激活函数**

使用 LeakyReLU 激活函数代替标准的 ReLU（Rectified Linear Unit）激活函数。LeakyReLU 允许负值通过一个小的线性比例因子，这有助于防止在训练过程中的死亡神经元问题。

**（2）在残差连接上使用平均池化**

如果 mod 为 True，则使用平均池化进行维度缩减。如果 mod 为 False，则使用 1x1 卷积和批量归一化来调整维度。

## lr_scheduler 学习率调度器

- `first_milestone`:150
- `second_milestone`: 250

代码使用 `MultiStepLR` 调度器，根据 `milestones` 列表在指定轮次（即150和250轮次）调整学习率 `lr=lr∗gamma`。

# 数据集加载

使用 `get_train_valid_loader()` 和 `get_test_loader()` 分别加载训练数据和测试数据，其中 `get_train_valid_loader()` 将训练数据分为训练集和验证集。

## get_train_valid_loader()

函数接收以下参数：

- `batch_size`: 每个批次加载的样本数量。
- `augment`: 是否对训练集应用数据增强。
- `val_seed`: 用于划分验证集的固定随机种子，以确保结果的可重复性。
- `val_size`: 从训练集中划分用于验证的数据集的比例。
- `num_workers`: 加载数据集时使用的子进程数量。
- `pin_memory`: 是否将张量复制到CUDA专用内存中，如果使用GPU，设置为True，默认值为False。

这段代码定义了一个名为 `get_train_valid_loader` 的函数，其目的是为 CIFAR-10 数据集加载和返回训练集和验证集的多进程迭代器。

- transform: 
   - 验证集 `valid_transform`，包括转换为张量和标准化。
   - 训练集 `train_transform`，包括转换为张量和标准化。同时根据 `augment` 参数，增加随机裁剪、随机水平翻转。

- 数据集加载与划分：
   - 加载训练数据，训练集和验证集分别应用之前定义的变换。
   - 使用随机种子打乱索引列表，根据 `val_size` 计算验证集大小 `split`，并划分训练集索引和验证集索引 `train_idx` 和 `valid_idx`。
   - 使用 `Subset` 创建训练集和验证集的数据子集。

- 返回结果：
  - 创建并返回 `train_loader` 和 `valid_loader`。

## get_test_loader()

整体流程与 get_train_valid_loader() 类似。

# 训练

## training deep ensemble models

- 解析命令行参数，用于控制训练过程中的各种设置，包括随机种子、`device` 等
- 创建模型集合。
- 初始化优化器和学习率调度器，默认为 `SGD` 和 `MultiStepLR`
- 为每个模型加载数据，`val_seed = args.seed + i`，确保不同模型的训练集不同。
- 训练循环。
   - 进行多个 `epoch` 的训练。
   - 对于每个 `epoch` 和每个模型，执行以下操作：
      - 使用 `train_single_epoch()` 函数训练单个 `epoch` 并记录训练损失。
      - 更新学习率调度器。
- 保存模型。如果当前 `epoch` 是args.save_interval的倍数，则保存模型的状态字典。

## training a single model for OOD detection

与 `training deep ensemble models` 类似，只是训练单个模型。

## train_single_epoch()

函数用于对模型进行单周期（epoch）的训练。参数列表如下：

- `epoch`：当前训练周期的索引。
- `model`：要训练的模型。
- `train_loader`：训练数据的加载器。
- `optimizer`：用于优化模型权重的优化器。
- `device`：模型和数据所使用的设备。
- `loss_function`：使用的损失函数，默认为 "cross_entropy"。
- `loss_mean`：是否对损失值取平均，默认为 False。

流程如下：

- 将模型设置为训练模式 `model.train()`。
- 遍历 `train_loader`：
   - 将数据和标签移动到 `device`。
   - 清除优化器的梯度 `optimizer.zero_grad()`。
   - 前向传播计算模型输出 `logits`。
   - 根据指定的损失函数计算损失 `loss`。
   - 如果 `loss_mean` 为 True，则将损失除以批次数据长度。
   - 反向传播 `loss.backward()`。
   - 累积损失并执行优化器更新 `optimizer.step()`。
   - 根据 `log_interval` 打印训练进度和损失信息。
- 打印并返回该周期的平均损失。
